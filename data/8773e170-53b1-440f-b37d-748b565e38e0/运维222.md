# devops

### **一、基础架构搭建**

#### 1. **Kubernetes 集群部署**

- 使用工具（如 `kubeadm`、`kops`、`Rancher` 或托管服务如 EKS/GKE/AKS）部署集群。
- 确保集群支持：
  - **持久化存储**（如 Longhorn、Ceph 或 CSI 驱动）
  - **网络插件**（如 Calico、Flannel）
  - **Ingress 控制器**（如 Nginx、Traefik）

#### 2. **代码仓库集成**

- 选择 Git 仓库（如 GitHub、GitLab、Gitea 或 Bitbucket）。
- 配置 Webhook 触发 CI/CD 流程。

------

### **二、CI/CD 流水线工具**

#### 1. **CI 工具选择**

- **Jenkins**：传统灵活，适合复杂流水线。
- **GitLab CI/CD**：内置 Git 仓库 + CI/CD，开箱即用。
- **Tekton**：云原生 CI/CD 框架，Kubernetes 原生。
- **Argo Workflows**：适合复杂任务编排。

#### 2. **CD 工具选择**

- **Argo CD**：GitOps 风格，自动同步集群状态与 Git 仓库。
- **Flux CD**：类似 Argo CD，轻量级。
- **Spinnaker**：多云部署支持。

------

### **三、自动化流水线设计**

#### 1. **代码提交阶段**

- 开发者推送代码到 Git 仓库，触发 Webhook。

- **示例流程**：

  yaml

  复制

  ```
  # GitLab CI 示例 (.gitlab-ci.yml)
  stages:
    - build
    - test
    - deploy
  
  build:
    image: docker:latest
    stage: build
    script:
      - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .
      - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
  
  test:
    image: alpine
    stage: test
    script:
      - echo "Running unit tests..."
  
  deploy:
    image: alpine/k8s
    stage: deploy
    script:
      - kubectl apply -f k8s-manifests/
  ```

#### 2. **镜像构建与推送**

- **Docker 镜像构建**：使用 `Dockerfile` 定义镜像。
- **安全构建**：使用 `Kaniko`（无需 Docker Daemon）或 `Buildah`。
- **镜像仓库**：集成私有仓库（如 Harbor）或公有仓库（Docker Hub、ECR）。

#### 3. **部署到 Kubernetes**

- **配置管理**：
  - 使用 `Helm` 打包应用。
  - 使用 `Kustomize` 管理多环境配置。
- **部署策略**：
  - 蓝绿部署（Blue-Green）
  - 金丝雀发布（Canary）
  - 滚动更新（Rolling Update）

#### 4. **环境隔离**

- 通过 Namespace 隔离开发、测试、生产环境。
- 使用 `Argo CD` 自动同步不同分支到不同环境。

------

### **四、基础设施即代码（IaC）**

#### 1. **Kubernetes 资源配置**

- 使用 YAML 文件或 Helm Chart 定义 Deployment、Service、Ingress 等。

- 示例 Helm 值文件：

  yaml

  复制

  ```
  # values.yaml
  replicaCount: 3
  image:
    repository: my-app
    tag: latest
  service:
    type: ClusterIP
    port: 80
  ```

#### 2. **配置与密钥管理**

- 使用 `ConfigMap` 和 `Secret` 存储配置。
- 集成 `Vault` 管理敏感信息。

------

### **五、监控与日志**

#### 1. **监控**

- 部署 `Prometheus` + `Grafana` 监控集群和应用指标。
- 使用 `kube-state-metrics` 收集集群状态。

#### 2. **日志**

- 使用 `EFK`（Elasticsearch + Fluentd + Kibana）或 `Loki` + `Promtail`。

------

### **六、安全加固**

#### 1. **RBAC**

- 为 CI/CD 工具和服务账号配置最小权限。

- 示例 Role 配置：

  yaml

  复制

  ```
  apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    namespace: dev
    name: deploy-role
  rules:
  - apiGroups: ["apps"]
    resources: ["deployments"]
    verbs: ["get", "create", "update"]
  ```

#### 2. **网络策略**

- 使用 `NetworkPolicy` 限制 Pod 间通信。

- 示例策略：

  yaml

  复制

  ```
  apiVersion: networking.k8s.io/v1
  kind: NetworkPolicy
  metadata:
    name: allow-app
  spec:
    podSelector:
      matchLabels:
        app: my-app
    ingress:
    - from:
      - podSelector:
          matchLabels:
            role: frontend
  ```

#### 3. **镜像扫描**

- 使用 `Trivy` 或 `Clair` 扫描镜像漏洞。

------

### **七、自助服务门户（可选）**

#### 1. **开发者界面**

- 使用 **Backstage** 或 **Jenkins X** 提供自助服务入口。
- 支持一键部署、查看日志、回滚版本。

#### 2. **CLI 工具**

- 提供自定义脚本或工具简化操作：

  bash

  复制

  ```
  # 示例 CLI 命令
  ./deploy.sh --env=prod --version=1.2.0
  ```

------

### **八、完整流程示例**

1. 开发者推送代码到 Git 仓库的 `dev` 分支。
2. Git 仓库触发 Jenkins/GitLab CI 流水线：
   - 构建 Docker 镜像并推送到 Harbor。
   - 运行单元测试和代码扫描。
3. Argo CD 检测到镜像更新，自动部署到 `dev` 环境。
4. 通过人工审批后，将代码合并到 `main` 分支，触发生产环境部署。

------

### **工具链总结**

| 功能     | 推荐工具                     |
| :------- | :--------------------------- |
| 代码仓库 | GitHub / GitLab / Gitea      |
| CI/CD    | GitLab CI / Tekton / Argo CD |
| 镜像构建 | Kaniko / Buildah             |
| 镜像仓库 | Harbor / ECR / Docker Hub    |
| 配置管理 | Helm / Kustomize             |
| 部署     | Argo CD / Flux               |
| 监控     | Prometheus + Grafana         |
| 日志     | Loki + Promtail              |
| 安全     | Vault / Trivy                |

通过以上步骤，可实现一个基于 Kubernetes 的简易 PaaS/DevOps 系统，覆盖代码提交到生产部署的全流程自动化。





# 日志监控

### **一、基础生存包（能投初级岗位）**

1. **知道日志是啥**
   - 能说清楚日志就是系统/软件的"日记本"，记录谁干了什么、有没有出错
   - 知道常见的日志类型（系统日志、应用日志、网络设备日志）
2. **会查Linux日志**
   - 会用 `tail -f` 实时看日志更新
   - 会用 `grep` 过滤关键字（比如 `grep "error" /var/log/syslog`）
   - 知道 `/var/log` 下各个日志文件是干啥的（比如 `auth.log` 看登录记录）
3. **用过基础监控工具**
   - 装过Zabbix/Prometheus监控CPU、内存（能看懂仪表盘红不红）
   - 用过Grafana画个简单的折线图（比如展示服务器流量变化）

------

### **二、进阶实战包（可投中级岗位）**

1. **日志分析三板斧**
   - **过滤异常**：能写正则表达式抓错误日志（比如 `ERROR|FAILED|Timeout`）
   - **统计频率**：用 `awk '{print $5}' | sort | uniq -c` 统计错误类型次数
   - **关联分析**：发现数据库卡顿时，能查同时段的网络流量和慢查询日志
2. **玩转ELK全家桶**
   - 搭过Elasticsearch+Logstash+Kibana（本地虚拟机搭起来就行）
   - 会写Logstash配置文件解析nginx日志（比如拆分IP、状态码）
   - 在Kibana里做过饼图看HTTP状态码分布（比如500错误的占比）
3. **自动化小能手**
   - 写Shell脚本定时清理30天前的日志（`find /logs -mtime +30 -delete`）
   - 用Python写个脚本，发现日志连续报错5次就发邮件告警（不会写代码可以用Zabbix触发器替代）

------

### **三、真实战场包（直接拿去面试）**

1. **故障排查案例**
   - 能说出实际例子：比如通过日志发现网站卡顿是因为数据库连接池耗尽
   - 面试时能模拟：给你一段Apache访问日志，分析哪个IP在暴力扫描（`grep "404" | awk '{print $1}' | sort | uniq -c | sort -nr`）
2. **业务场景理解**
   - 知道不同日志的用途：
     - Nginx访问日志 → 分析用户行为
     - Java应用日志 → 排查代码报错
     - 系统日志 `/var/log/messages` → 定位硬件故障
3. **性能优化意识**
   - 发现日志量太大时，会配置日志轮转（logrotate）
   - 知道给ES集群分片能提升日志检索速度

------

### **四、投简历的底气（对照自查）**

- **如果达到以下水平，可以大胆投初级运维岗**：
  ✅ 能看懂日志里的报错信息（比如OOM、Connection refused）
  ✅ 会用ELK或者Grafana查日志（不要求调优集群）
  ✅ 写过简单的监控脚本（比如磁盘超过80%就告警）
  ✅ 面试能说清楚一次自己排查日志的经历（哪怕是实验室项目）
- **如果还不会**：
  ❌ 先别投：完全没碰过Linux命令行
  ❌ 先别投：不知道502和504状态码的区别
  ❌ 先别投：所有经验都停留在理论没动手实操过

------

### **五、快速上手指南**

1. **1天实战**：在自己电脑装个VMware，搭个WordPress网站，故意制造错误（比如关数据库），然后查nginx和mysql日志找原因。
2. **3天项目**：用ELK分析自己SSH登录日志，统计哪些IP尝试暴力破解（面试时这就是一个安全运维案例）。
3. **简历写法**：
   - 不要写“熟悉Linux” → 改成“通过日志排查过服务器内存泄漏问题”
   - 不要写“了解ELK” → 改成“搭建ELK实现Nginx访问日志可视化”

------

**总结**：运维岗其实很务实，不需要你精通所有理论，关键是能动手解决问题。当你：

1. 能独立分析日志找到常见问题（比如服务崩溃、磁盘满了）
2. 会用一个主流监控工具（Zabbix/Prometheus任选）
3. 能说出2-3个自己折腾日志的真实案例（哪怕是虚拟机里模拟的）
   **就可以开始投简历了**，剩下的技能可以在工作中边干边学！